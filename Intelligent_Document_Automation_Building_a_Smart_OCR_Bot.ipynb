{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Resume Dataset"
      ],
      "metadata": {
        "id": "8FH86Ll421aA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting the data"
      ],
      "metadata": {
        "id": "VGhsMmEb4Dzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting 20 random resume samples"
      ],
      "metadata": {
        "id": "wa5ISCZPAH0-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzqHUaZ3f7oL",
        "outputId": "1c5a2c84-fd3c-4dcb-8ff3-5893eaabb1bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'resume-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/resume-dataset\n",
            "\n",
            "20 Random samples from the dataset:\n",
            "/kaggle/input/resume-dataset/data/data/TEACHER/10504237.pdf\n",
            "/kaggle/input/resume-dataset/data/data/ARTS/20488267.pdf\n",
            "/kaggle/input/resume-dataset/data/data/ADVOCATE/17847636.pdf\n",
            "/kaggle/input/resume-dataset/data/data/APPAREL/19714635.pdf\n",
            "/kaggle/input/resume-dataset/data/data/ADVOCATE/28206098.pdf\n",
            "/kaggle/input/resume-dataset/data/data/BUSINESS-DEVELOPMENT/29908929.pdf\n",
            "/kaggle/input/resume-dataset/data/data/DIGITAL-MEDIA/27419236.pdf\n",
            "/kaggle/input/resume-dataset/data/data/ACCOUNTANT/19446337.pdf\n",
            "/kaggle/input/resume-dataset/data/data/APPAREL/12122372.pdf\n",
            "/kaggle/input/resume-dataset/data/data/CHEF/18036030.pdf\n",
            "/kaggle/input/resume-dataset/data/data/FINANCE/39675895.pdf\n",
            "/kaggle/input/resume-dataset/data/data/DESIGNER/14014749.pdf\n",
            "/kaggle/input/resume-dataset/data/data/BANKING/17818707.pdf\n",
            "/kaggle/input/resume-dataset/data/data/FINANCE/28758002.pdf\n",
            "/kaggle/input/resume-dataset/data/data/CONSTRUCTION/17252448.pdf\n",
            "/kaggle/input/resume-dataset/data/data/ACCOUNTANT/63137898.pdf\n",
            "/kaggle/input/resume-dataset/data/data/CONSTRUCTION/10176013.pdf\n",
            "/kaggle/input/resume-dataset/data/data/DESIGNER/12547982.pdf\n",
            "/kaggle/input/resume-dataset/data/data/AVIATION/24668861.pdf\n",
            "/kaggle/input/resume-dataset/data/data/CONSTRUCTION/30397268.pdf\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"snehaanbhawal/resume-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# Get a list of all files in the dataset directory\n",
        "all_files = []\n",
        "for root, dirs, files in os.walk(path):\n",
        "    for file in files:\n",
        "        all_files.append(os.path.join(root, file))\n",
        "\n",
        "# Get 20 random samples\n",
        "random_samples = random.sample(all_files, 20)\n",
        "\n",
        "print(\"\\n20 Random samples from the dataset:\")\n",
        "for sample in random_samples:\n",
        "    print(sample)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting pdf to image"
      ],
      "metadata": {
        "id": "r2nafs-TAa2M"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b38f0fd",
        "outputId": "60dfad33-58df-44b1-f066-7334c52a6e0b"
      },
      "source": [
        "!apt-get install poppler-utils\n",
        "!pip install pdf2image"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.11 [186 kB]\n",
            "Fetched 186 kB in 1s (269 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.11_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.11) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.11) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pdf2image) (11.3.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "372b73bd",
        "outputId": "433772b3-7808-417e-ed18-89343342e727"
      },
      "source": [
        "from pdf2image import convert_from_path\n",
        "\n",
        "output_folder = \"/content/resume_images\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for pdf_path in random_samples:\n",
        "    try:\n",
        "        pages = convert_from_path(pdf_path)\n",
        "        image_name = os.path.basename(pdf_path).replace('.pdf', '.jpg')\n",
        "        image_path = os.path.join(output_folder, image_name)\n",
        "        pages[0].save(image_path, 'JPEG')\n",
        "        print(f\"Converted {pdf_path} to {image_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error converting {pdf_path}: {e}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted /kaggle/input/resume-dataset/data/data/TEACHER/10504237.pdf to /content/resume_images/10504237.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/ARTS/20488267.pdf to /content/resume_images/20488267.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/ADVOCATE/17847636.pdf to /content/resume_images/17847636.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/APPAREL/19714635.pdf to /content/resume_images/19714635.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/ADVOCATE/28206098.pdf to /content/resume_images/28206098.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/BUSINESS-DEVELOPMENT/29908929.pdf to /content/resume_images/29908929.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/DIGITAL-MEDIA/27419236.pdf to /content/resume_images/27419236.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/ACCOUNTANT/19446337.pdf to /content/resume_images/19446337.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/APPAREL/12122372.pdf to /content/resume_images/12122372.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/CHEF/18036030.pdf to /content/resume_images/18036030.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/FINANCE/39675895.pdf to /content/resume_images/39675895.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/DESIGNER/14014749.pdf to /content/resume_images/14014749.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/BANKING/17818707.pdf to /content/resume_images/17818707.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/FINANCE/28758002.pdf to /content/resume_images/28758002.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/CONSTRUCTION/17252448.pdf to /content/resume_images/17252448.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/ACCOUNTANT/63137898.pdf to /content/resume_images/63137898.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/CONSTRUCTION/10176013.pdf to /content/resume_images/10176013.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/DESIGNER/12547982.pdf to /content/resume_images/12547982.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/AVIATION/24668861.pdf to /content/resume_images/24668861.jpg\n",
            "Converted /kaggle/input/resume-dataset/data/data/CONSTRUCTION/30397268.pdf to /content/resume_images/30397268.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Preprocesing: OpenCV"
      ],
      "metadata": {
        "id": "2hceoxEPGrid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install opencv-python matplotlib numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waLbGcS01y9v",
        "outputId": "19712723-26f0-4c01-b2c9-077c2ef8ffbb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def display_image(image, title=\"Image\"):\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_MXQ3uyEHJSG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the image to grayscale\n",
        "def convert_to_grayscale(image):\n",
        "  return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
      ],
      "metadata": {
        "id": "MkgZ-0lKHQwi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def reduce_noise(gray_image):\n",
        "  return cv2.GaussianBlur(gray_image, (5, 5), 0)"
      ],
      "metadata": {
        "id": "98a_P6MCHxM-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binarize_image(blur_reduced_image):\n",
        "  return cv2.adaptiveThreshold(\n",
        "    blur_reduced_image,\n",
        "    255,\n",
        "    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "    cv2.THRESH_BINARY, # Invert the colors (text becomes white because of matplotlib)\n",
        "    11, # Block size\n",
        "    4  # Constant C\n",
        "  )"
      ],
      "metadata": {
        "id": "WriI9eZ9ISEc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def deskew_image(image):\n",
        "    \"\"\"\n",
        "    Corrects the skew of an image by finding the minimum area rectangle\n",
        "    of the text block and rotating accordingly.\n",
        "    \"\"\"\n",
        "    # Find all non-zero (white) pixels\n",
        "    coords = cv2.findNonZero(image)\n",
        "\n",
        "    # Get the minimum area bounding rectangle\n",
        "    # It returns (center(x,y), (width, height), angle of rotation)\n",
        "    rect = cv2.minAreaRect(coords)\n",
        "    angle = rect[-1] - 90\n",
        "\n",
        "    # The `cv2.minAreaRect` angle has a specific range.\n",
        "    # We need to adjust it for our rotation.\n",
        "    if angle < -45:\n",
        "        angle = -(90 + angle)\n",
        "    else:\n",
        "        angle = angle\n",
        "\n",
        "    # Get the rotation matrix and rotate the image\n",
        "    (h, w) = image.shape[:2]\n",
        "    center = (w // 2, h // 2)\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    rotated = cv2.warpAffine(image, M, (w, h),\n",
        "                             flags=cv2.INTER_CUBIC,\n",
        "                             borderMode=cv2.BORDER_REPLICATE)\n",
        "    print(f\"Detected skew angle: {angle:.2f} degrees\")\n",
        "\n",
        "    # Now, rotate the original grayscale image by the same angle\n",
        "    (h, w) = rotated.shape\n",
        "    center = (w // 2, h // 2)\n",
        "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
        "    deskewed_gray = cv2.warpAffine(rotated, M, (w, h),\n",
        "                                  flags=cv2.INTER_CUBIC,\n",
        "                                  borderMode=cv2.BORDER_REPLICATE)\n",
        "\n",
        "    return deskewed_gray"
      ],
      "metadata": {
        "id": "7dz6UZWCJN6_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run the above code for all images"
      ],
      "metadata": {
        "id": "ENBAmUKyM_fj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_one_image(image):\n",
        "  image = convert_to_grayscale(image)\n",
        "  print(\"Converted image to grayscale..\")\n",
        "  image = reduce_noise(image)\n",
        "  print(\"Reduced noise in the image..\")\n",
        "  image = binarize_image(image)\n",
        "  print(\"Binarized the image..\")\n",
        "  image = deskew_image(image)\n",
        "  print(\"Corrected image orientation..\")\n",
        "  return image"
      ],
      "metadata": {
        "id": "MIxeyWXOKFdZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "input_folder_path = \"/content/resume_images\"\n",
        "output_folder_path = \"/content/processed_images\" # Changed output folder name\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "if os.makedirs(output_folder_path, exist_ok=True):\n",
        "  print(f\"Created folder: {output_folder_path}\")\n",
        "\n",
        "# Get a list of image files in the input folder\n",
        "image_files = [f for f in os.listdir(input_folder_path) if f.endswith('.jpg')] # Filter for jpg files\n",
        "\n",
        "print(f\"Processing {len(image_files)} images...\") # Print the number of images being processed\n",
        "\n",
        "for i, image_name in enumerate(image_files[:20], 1): # Iterate through the image files\n",
        "  print(f\"Processing image {i}/{len(image_files)}: {image_name}\")\n",
        "  image_path = os.path.join(input_folder_path, image_name)\n",
        "  image = cv2.imread(image_path)\n",
        "\n",
        "  if image is None: # Check if image loading was successful\n",
        "      print(f\"Warning: Could not load image {image_path}. Skipping.\")\n",
        "      print(\"-\" * 50)\n",
        "      continue\n",
        "\n",
        "  processed_image = process_one_image(image)\n",
        "  # save image\n",
        "  output_path = os.path.join(output_folder_path, image_name)\n",
        "  cv2.imwrite(output_path, processed_image)\n",
        "  print(f\"Saved processed image to: {output_path}\")\n",
        "  print(\"-\"*50)\n",
        "\n",
        "print(\"Processing images is completed.\")\n",
        "print(f\"Total time taken: {time.time() - start_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL8hhsuENS29",
        "outputId": "cc6d6f74-ab77-4075-aa50-d68ba06bfe7f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 20 images...\n",
            "Processing image 1/20: 10504237.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/10504237.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 2/20: 28206098.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/28206098.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 3/20: 18036030.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/18036030.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 4/20: 17252448.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/17252448.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 5/20: 12547982.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/12547982.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 6/20: 63137898.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/63137898.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 7/20: 24668861.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/24668861.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 8/20: 29908929.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/29908929.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 9/20: 14014749.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/14014749.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 10/20: 10176013.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/10176013.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 11/20: 28758002.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/28758002.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 12/20: 12122372.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/12122372.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 13/20: 27419236.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/27419236.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 14/20: 19714635.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/19714635.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 15/20: 30397268.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/30397268.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 16/20: 20488267.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/20488267.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 17/20: 39675895.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/39675895.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 18/20: 17847636.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/17847636.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 19/20: 19446337.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/19446337.jpg\n",
            "--------------------------------------------------\n",
            "Processing image 20/20: 17818707.jpg\n",
            "Converted image to grayscale..\n",
            "Reduced noise in the image..\n",
            "Binarized the image..\n",
            "Detected skew angle: 0.00 degrees\n",
            "Corrected image orientation..\n",
            "Saved processed image to: /content/processed_images/17818707.jpg\n",
            "--------------------------------------------------\n",
            "Processing images is completed.\n",
            "Total time taken: 15.325383186340332 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation\n",
        "`pip install pytesseract pillow`"
      ],
      "metadata": {
        "id": "OFN_cFkbQMwX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Tesseract\n",
        "\n",
        "For developers, integrating Tesseract into an application is straightforward using its API. Here is a simple example using the `pytesseract` wrapper in Python:\n",
        "\n",
        "```python\n",
        "\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "\n",
        "\n",
        "text = pytesseract.image_to_string(Image.open(filename))\n",
        "\n",
        "print(text)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "UNYLJzghPpno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pytesseract pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUu8FdXBNgHn",
        "outputId": "a6d0c8c8-bd3a-42d9-b9be-55a4cf79686d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import pytesseract\n",
        "import os\n",
        "\n",
        "processed_image_folder = '/content/processed_images'\n",
        "\n",
        "# Get a list of files in the processed images folder\n",
        "processed_images = os.listdir(processed_image_folder)\n",
        "\n",
        "# Check if there are any processed images\n",
        "if processed_images:\n",
        "    # Take the first image file found\n",
        "    sample_image_name = processed_images[0]\n",
        "    sample_image_path = os.path.join(processed_image_folder, sample_image_name)\n",
        "\n",
        "    print(f\"Using sample image: {sample_image_path}\")\n",
        "\n",
        "    # Perform OCR on the sample image\n",
        "    text = pytesseract.image_to_string(Image.open(sample_image_path))\n",
        "\n",
        "    print(\"\\nExtracted Text:\")\n",
        "    print(text)\n",
        "else:\n",
        "    print(f\"No processed images found in {processed_image_folder}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-HuQ42EQm6X",
        "outputId": "378cfeb2-66a3-434b-dea0-7a5a32d42718"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using sample image: /content/processed_images/10504237.jpg\n",
            "\n",
            "Extracted Text:\n",
            "BIOLOGY TEACHER\n",
            "\n",
            "Experience\n",
            "\n",
            "11/2016 to Current\n",
            "\n",
            "Biology Teacher Company Name 1% City , State\n",
            "\n",
            "* Execute, impkment, and modify kesson plans while incorporating differentiated instruction and multiple intelligences.\n",
            "\n",
            "© Design and align lessons, labs, and assessments incorporating STEM, problem based karning, Common Core and NGSS.\n",
            "\n",
            "© Volunteer and participate in schools extracurricular activities such as selling tickets for the school talent show and participating in the\n",
            "Lindenwold HS 5K for the scholarship fimd.\n",
            "\n",
            "© Teach and translate materials utilizing Sheltered Instruction techniques for English Language Learners.\n",
            "\n",
            "© Co-teach with special education teachers while executing modifications in student IEP and 504 plans.\n",
            "\n",
            "* Plan and present Google applications training for Lmdenwold HS professional development.\n",
            "\n",
            "09/2011 to 11/2016\n",
            "Biology Teacher Company Name 1% City, State\n",
            "\n",
            "© Seck out of district professional development opportunities including but not limited to NJEA and NSTA Conventions, and addition\n",
            "programs focused in science, standards, & STEM.\n",
            "\n",
            "© Successfillly fimdraise money for incorporating additional technologies, TI Nspire CX graphing calculators, for the classroom through\n",
            "\n",
            "DonorsChoose.org.\n",
            "\n",
            "Execute, impkment, and modify lesson plans while incorporating differentiated instruction and multiple intelligences.\n",
            "\n",
            "Design and align lessons, labs, and assessments incorporating STEM, problem based karning, Common Core and NGSS.\n",
            "\n",
            "Impknent ideas, practices, and theories from professional development workshops.\n",
            "\n",
            "Tum Key for other teachers).\n",
            "\n",
            "Co-teach with special education teachers while executing modifications in student IEP and 504 plans.\n",
            "\n",
            "Communicate with parents/guardians regarding student progress within the classroom\n",
            "\n",
            "* Achieve Level 1 Google Certified Educator status in October 2016.\n",
            "\n",
            "01/2011 to 03/2011\n",
            "Student Teacher Company Name 1% City, State\n",
            "\n",
            "¢ Develop hbs, assignments, and projects to reinforce material taught previously encouraging deeper knowledge and understanding in\n",
            "addition to incorporate multiple disciplines, including writing, science, social sciences, and health,\n",
            "\n",
            "* Continuous educational improverrent by applying constructive criticism to lessons during student teaching experience.\n",
            "\n",
            "© Formative and sunmntive assessments of students on content related to the New Jersey State standards.\n",
            "\n",
            "© Execute and implement lesson plans for the week while ensuring differentiated instruction.\n",
            "\n",
            "* Communicated with parents/guardians about student progress within the chssroom.\n",
            "\n",
            "04/2007 to 04/2011\n",
            "\n",
            "Clmical Lab Manager/Technologist Company Name i City , State\n",
            "\n",
            "¢ Educate and train Pathology Residents according to guidelines set forth in Mokcular Diagnostic Laboratory Resident Manual, including\n",
            "observation and hands on bench training of laboratory procedures and techniques.\n",
            "\n",
            "© Research and validate new laboratory tests by determining parameters for sample concentration, detection limits, and composition of\n",
            "procedures for the laboratory.\n",
            "\n",
            "¢ Maintain failed run, repeat testing, instrument/equipment maintenance & calibration, QC temperature, & T-A-T logs.\n",
            "\n",
            "* PerformDNA extraction/quantitation, PCR, CE, interpretation, and reporting of results of molecular studies.\n",
            "\n",
            "© Manage and operate the laboratory and equipment according to the QA/QC Procedure and Protocol.\n",
            "\n",
            "08/2005 to 04/2007\n",
            "Quality Control Technician - TCA/E Coordinator Company Name 1 City , State\n",
            "\n",
            "Coordinate monthly seminar with QC Director and attending laboratory technicians in addition to conducting ‘Good Laboratory Practices’\n",
            "and orientation kectures for hboratory technicians.\n",
            "\n",
            "Compose and administer seminar quizzes and verifying technician credit by monitoring seminar attendance.\n",
            "Assemble and execute state reports for Department of Health in several states in which licenses are held.\n",
            "Troubleshoot and investigate pending specimens to ensure results are reported within a timely manner.\n",
            "Manage Technician Competency Assessment (TCA) and Continuing Education (TCE) Programs.\n",
            "Maintain laboratory technician training records and schedule annual evaluations.\n",
            "\n",
            "Accumuhte test result and testing comments for final report compketion.\n",
            "\n",
            "Compose standard operations and procedure for pending specimens.\n",
            "\n",
            "Verify patient requisition forms to records in company database.\n",
            "\n",
            "Compile and maintained list of specimens pending.\n",
            "\n",
            "01/2005 to 08/2005\n",
            "Clmical Laboratory Technician Company Name iA City , State\n",
            "\n",
            "e Prenare orl agars and asencinter| cnhstrates fram raw material in laroe-seale eleetmnhoarmsic testine nlatiarm\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import pytesseract\n",
        "import time\n",
        "\n",
        "input_folder_path = \"/content/processed_images\"\n",
        "output_folder_path = \"/content/tesseract_output\"\n",
        "start_time = time.time()\n",
        "\n",
        "if os.makedirs(output_folder_path, exist_ok=True):\n",
        "  print(f\"Created folder: {output_folder_path}\")\n",
        "\n",
        "total_images = sum(1 for entry in os.scandir(input_folder_path))\n",
        "print(f\"Total images in folder: {total_images}\")\n",
        "\n",
        "for i, image_name in enumerate(os.listdir(input_folder_path)[:20], 1):\n",
        "  print(f\"Processing image {i}/{total_images}: {image_name}\")\n",
        "  image_path = os.path.join(input_folder_path, image_name)\n",
        "  print(\"Extracting text from image..\")\n",
        "  text = pytesseract.image_to_string(Image.open(image_path))\n",
        "  output_path = os.path.join(output_folder_path, image_name.replace(\".jpg\", \".txt\"))\n",
        "  with open(output_path, \"w\") as f:\n",
        "    f.write(text)\n",
        "\n",
        "  print(f\"Saved extracted text to {output_path}\")\n",
        "  print(\"-\"*50)\n",
        "\n",
        "print(\"Text Extraction Completed.\")\n",
        "print(f\"Total time taken: {time.time() - start_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aDgO1_RRRD7",
        "outputId": "63dcd483-6ee9-47df-c4ee-8d88a64ed0ce"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images in folder: 20\n",
            "Processing image 1/20: 10504237.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/10504237.txt\n",
            "--------------------------------------------------\n",
            "Processing image 2/20: 28206098.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/28206098.txt\n",
            "--------------------------------------------------\n",
            "Processing image 3/20: 18036030.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/18036030.txt\n",
            "--------------------------------------------------\n",
            "Processing image 4/20: 17252448.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/17252448.txt\n",
            "--------------------------------------------------\n",
            "Processing image 5/20: 12547982.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/12547982.txt\n",
            "--------------------------------------------------\n",
            "Processing image 6/20: 63137898.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/63137898.txt\n",
            "--------------------------------------------------\n",
            "Processing image 7/20: 24668861.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/24668861.txt\n",
            "--------------------------------------------------\n",
            "Processing image 8/20: 29908929.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/29908929.txt\n",
            "--------------------------------------------------\n",
            "Processing image 9/20: 14014749.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/14014749.txt\n",
            "--------------------------------------------------\n",
            "Processing image 10/20: 10176013.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/10176013.txt\n",
            "--------------------------------------------------\n",
            "Processing image 11/20: 28758002.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/28758002.txt\n",
            "--------------------------------------------------\n",
            "Processing image 12/20: 12122372.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/12122372.txt\n",
            "--------------------------------------------------\n",
            "Processing image 13/20: 27419236.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/27419236.txt\n",
            "--------------------------------------------------\n",
            "Processing image 14/20: 19714635.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/19714635.txt\n",
            "--------------------------------------------------\n",
            "Processing image 15/20: 30397268.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/30397268.txt\n",
            "--------------------------------------------------\n",
            "Processing image 16/20: 20488267.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/20488267.txt\n",
            "--------------------------------------------------\n",
            "Processing image 17/20: 39675895.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/39675895.txt\n",
            "--------------------------------------------------\n",
            "Processing image 18/20: 17847636.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/17847636.txt\n",
            "--------------------------------------------------\n",
            "Processing image 19/20: 19446337.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/19446337.txt\n",
            "--------------------------------------------------\n",
            "Processing image 20/20: 17818707.jpg\n",
            "Extracting text from image..\n",
            "Saved extracted text to /content/tesseract_output/17818707.txt\n",
            "--------------------------------------------------\n",
            "Text Extraction Completed.\n",
            "Total time taken: 155.12392044067383 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Information Extraction"
      ],
      "metadata": {
        "id": "YpSOX0qLV5GT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Extract the following information from the given resume:\n",
        "- Name\n",
        "- Contact Information (phone, email, LinkedIn, etc.)\n",
        "- Summary/Objective\n",
        "- Work Experience (company, job title, dates, responsibilities)\n",
        "- Education (degree, major, institution, graduation date)\n",
        "- Skills\n",
        "\n",
        "The resume has been processed (converted to grayscale, noise reduced, binarized, and deskewed) using OpenCV, and text has been extracted using Tesseract.\n",
        "Use the extracted text as support for extracting information.\n",
        "If you believe the text extraction is incorrect somewhere, you may correct it yourself and provide corrected information.\n",
        "Always give your response in the following JSON format:\n",
        "{\n",
        "    \"name\": \"NAME\",\n",
        "    \"contact_information\": {\n",
        "        \"phone\": \"PHONE_NUMBER\",\n",
        "        \"email\": \"EMAIL_ADDRESS\",\n",
        "        \"linkedin\": \"LINKEDIN_PROFILE_URL\"\n",
        "        // Add other relevant contact details\n",
        "    },\n",
        "    \"summary\": \"SUMMARY_TEXT\",\n",
        "    \"work_experience\": [\n",
        "        {\n",
        "            \"company\": \"COMPANY_NAME\",\n",
        "            \"job_title\": \"JOB_TITLE\",\n",
        "            \"dates\": \"START_DATE - END_DATE\",\n",
        "            \"responsibilities\": [\"RESPONSIBILITY 1\", \"RESPONSIBILITY 2\"]\n",
        "        }\n",
        "        // Add other work experiences\n",
        "    ],\n",
        "    \"education\": [\n",
        "        {\n",
        "            \"degree\": \"DEGREE\",\n",
        "            \"major\": \"MAJOR\",\n",
        "            \"institution\": \"INSTITUTION_NAME\",\n",
        "            \"graduation_date\": \"GRADUATION_DATE\"\n",
        "        }\n",
        "        // Add other educational degrees\n",
        "    ],\n",
        "    \"skills\": [\"SKILL 1\", \"SKILL 2\"]\n",
        "}\n",
        "Respond with the extracted information only in the specified format.\n",
        "Here is the extracted text:\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "OIAD13ghSVim"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.colab import userdata # colab only code\n",
        "from PIL import Image\n",
        "import json\n",
        "import time"
      ],
      "metadata": {
        "id": "UIieP2YPWywq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
      ],
      "metadata": {
        "id": "iasUPntIBOSa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder_path = \"/content/processed_images\"\n",
        "text_folder_path = \"/content/tesseract_output\"\n",
        "output_folder_path = \"/content/json_output\"\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "if os.makedirs(output_folder_path, exist_ok=True):\n",
        "  print(f\"Created folder: {output_folder_path}\")\n",
        "\n",
        "total_images = sum(1 for entry in os.scandir(image_folder_path))\n",
        "print(f\"Total images in folder: {total_images}\")\n",
        "\n",
        "# Initialize the Gemini model\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "for i, image_name in enumerate(os.listdir(image_folder_path)[:20], 1):\n",
        "  print(f\"Processing image {i}/{total_images}: {image_name}\")\n",
        "  image_path = os.path.join(image_folder_path, image_name)\n",
        "  print(f\"Loading image: {image_path}\")\n",
        "  with open(image_path, \"rb\") as f:\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "\n",
        "  text_path = os.path.join(text_folder_path, image_name.replace(\".jpg\", \".txt\"))\n",
        "  print(f\"Loading extracted text: {text_path}\")\n",
        "  with open(text_path, \"r\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "  print(\"Extracting information from image and text..\")\n",
        "\n",
        "  full_prompt = prompt + text\n",
        "\n",
        "  contents = [\n",
        "        image,\n",
        "        {\n",
        "            \"text\": full_prompt\n",
        "        }\n",
        "    ]\n",
        "  response = model.generate_content(contents=contents)\n",
        "\n",
        "  # Access the usage_metadata attribute\n",
        "  usage_metadata = response.usage_metadata\n",
        "\n",
        "  # Print the different token counts\n",
        "  print(f\"Input Token Count: {usage_metadata.prompt_token_count}\")\n",
        "  print(f\"Output Token Count: {usage_metadata.candidates_token_count}\")\n",
        "  print(f\"Total Token Count: {usage_metadata.total_token_count}\")\n",
        "\n",
        "  try:\n",
        "      extracted_information = json.loads(response.text.replace('```json', '').replace('```', ''))\n",
        "      output_path = os.path.join(output_folder_path, image_name.replace(\".jpg\", \".json\"))\n",
        "      with open(output_path, \"w\") as f:\n",
        "        json.dump(extracted_information, f, indent=4)\n",
        "\n",
        "      print(f\"Saved extracted information to {output_path}\")\n",
        "  except json.JSONDecodeError as e:\n",
        "      print(f\"Error decoding JSON for {image_name}: {e}\")\n",
        "      print(f\"Response text: {response.text}\")\n",
        "\n",
        "  print(\"-\"*50)\n",
        "  time.sleep(1) # Added a small delay to avoid hitting API limits\n",
        "\n",
        "\n",
        "print(\"Information Extraction Completed.\")\n",
        "print(f\"Total time taken: {time.time() - start_time} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OgKSdTovXReV",
        "outputId": "07dbecad-2d18-4698-935b-afdbe6624b36"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total images in folder: 20\n",
            "Processing image 1/20: 10504237.jpg\n",
            "Loading image: /content/processed_images/10504237.jpg\n",
            "Loading extracted text: /content/tesseract_output/10504237.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1596\n",
            "Output Token Count: 1606\n",
            "Total Token Count: 5283\n",
            "Saved extracted information to /content/json_output/10504237.json\n",
            "--------------------------------------------------\n",
            "Processing image 2/20: 28206098.jpg\n",
            "Loading image: /content/processed_images/28206098.jpg\n",
            "Loading extracted text: /content/tesseract_output/28206098.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1321\n",
            "Output Token Count: 903\n",
            "Total Token Count: 4460\n",
            "Saved extracted information to /content/json_output/28206098.json\n",
            "--------------------------------------------------\n",
            "Processing image 3/20: 18036030.jpg\n",
            "Loading image: /content/processed_images/18036030.jpg\n",
            "Loading extracted text: /content/tesseract_output/18036030.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1333\n",
            "Output Token Count: 913\n",
            "Total Token Count: 4021\n",
            "Saved extracted information to /content/json_output/18036030.json\n",
            "--------------------------------------------------\n",
            "Processing image 4/20: 17252448.jpg\n",
            "Loading image: /content/processed_images/17252448.jpg\n",
            "Loading extracted text: /content/tesseract_output/17252448.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1285\n",
            "Output Token Count: 697\n",
            "Total Token Count: 3338\n",
            "Saved extracted information to /content/json_output/17252448.json\n",
            "--------------------------------------------------\n",
            "Processing image 5/20: 12547982.jpg\n",
            "Loading image: /content/processed_images/12547982.jpg\n",
            "Loading extracted text: /content/tesseract_output/12547982.txt\n",
            "Extracting information from image and text..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 5129.14ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Token Count: 1432\n",
            "Output Token Count: 1035\n",
            "Total Token Count: 2858\n",
            "Saved extracted information to /content/json_output/12547982.json\n",
            "--------------------------------------------------\n",
            "Processing image 6/20: 63137898.jpg\n",
            "Loading image: /content/processed_images/63137898.jpg\n",
            "Loading extracted text: /content/tesseract_output/63137898.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1464\n",
            "Output Token Count: 1127\n",
            "Total Token Count: 4205\n",
            "Saved extracted information to /content/json_output/63137898.json\n",
            "--------------------------------------------------\n",
            "Processing image 7/20: 24668861.jpg\n",
            "Loading image: /content/processed_images/24668861.jpg\n",
            "Loading extracted text: /content/tesseract_output/24668861.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1262\n",
            "Output Token Count: 666\n",
            "Total Token Count: 2527\n",
            "Saved extracted information to /content/json_output/24668861.json\n",
            "--------------------------------------------------\n",
            "Processing image 8/20: 29908929.jpg\n",
            "Loading image: /content/processed_images/29908929.jpg\n",
            "Loading extracted text: /content/tesseract_output/29908929.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1332\n",
            "Output Token Count: 934\n",
            "Total Token Count: 3175\n",
            "Saved extracted information to /content/json_output/29908929.json\n",
            "--------------------------------------------------\n",
            "Processing image 9/20: 14014749.jpg\n",
            "Loading image: /content/processed_images/14014749.jpg\n",
            "Loading extracted text: /content/tesseract_output/14014749.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1442\n",
            "Output Token Count: 1098\n",
            "Total Token Count: 5128\n",
            "Saved extracted information to /content/json_output/14014749.json\n",
            "--------------------------------------------------\n",
            "Processing image 10/20: 10176013.jpg\n",
            "Loading image: /content/processed_images/10176013.jpg\n",
            "Loading extracted text: /content/tesseract_output/10176013.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1486\n",
            "Output Token Count: 990\n",
            "Total Token Count: 4520\n",
            "Saved extracted information to /content/json_output/10176013.json\n",
            "--------------------------------------------------\n",
            "Processing image 11/20: 28758002.jpg\n",
            "Loading image: /content/processed_images/28758002.jpg\n",
            "Loading extracted text: /content/tesseract_output/28758002.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1625\n",
            "Output Token Count: 1312\n",
            "Total Token Count: 6264\n",
            "Saved extracted information to /content/json_output/28758002.json\n",
            "--------------------------------------------------\n",
            "Processing image 12/20: 12122372.jpg\n",
            "Loading image: /content/processed_images/12122372.jpg\n",
            "Loading extracted text: /content/tesseract_output/12122372.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1271\n",
            "Output Token Count: 967\n",
            "Total Token Count: 3866\n",
            "Saved extracted information to /content/json_output/12122372.json\n",
            "--------------------------------------------------\n",
            "Processing image 13/20: 27419236.jpg\n",
            "Loading image: /content/processed_images/27419236.jpg\n",
            "Loading extracted text: /content/tesseract_output/27419236.txt\n",
            "Extracting information from image and text..\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:503 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 5617.88ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Token Count: 1828\n",
            "Output Token Count: 1434\n",
            "Total Token Count: 7259\n",
            "Saved extracted information to /content/json_output/27419236.json\n",
            "--------------------------------------------------\n",
            "Processing image 14/20: 19714635.jpg\n",
            "Loading image: /content/processed_images/19714635.jpg\n",
            "Loading extracted text: /content/tesseract_output/19714635.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1357\n",
            "Output Token Count: 613\n",
            "Total Token Count: 4484\n",
            "Saved extracted information to /content/json_output/19714635.json\n",
            "--------------------------------------------------\n",
            "Processing image 15/20: 30397268.jpg\n",
            "Loading image: /content/processed_images/30397268.jpg\n",
            "Loading extracted text: /content/tesseract_output/30397268.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1627\n",
            "Output Token Count: 1139\n",
            "Total Token Count: 4449\n",
            "Saved extracted information to /content/json_output/30397268.json\n",
            "--------------------------------------------------\n",
            "Processing image 16/20: 20488267.jpg\n",
            "Loading image: /content/processed_images/20488267.jpg\n",
            "Loading extracted text: /content/tesseract_output/20488267.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1299\n",
            "Output Token Count: 688\n",
            "Total Token Count: 4252\n",
            "Saved extracted information to /content/json_output/20488267.json\n",
            "--------------------------------------------------\n",
            "Processing image 17/20: 39675895.jpg\n",
            "Loading image: /content/processed_images/39675895.jpg\n",
            "Loading extracted text: /content/tesseract_output/39675895.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1698\n",
            "Output Token Count: 1296\n",
            "Total Token Count: 3795\n",
            "Error decoding JSON for 39675895.jpg: Expecting property name enclosed in double quotes: line 22 column 9 (char 1784)\n",
            "Response text: ```json\n",
            "{\n",
            "    \"name\": null,\n",
            "    \"contact_information\": {\n",
            "        \"phone\": null,\n",
            "        \"email\": null,\n",
            "        \"linkedin\": null\n",
            "    },\n",
            "    \"summary\": \"High-performing Senior Director of Finance with management experience, and exceptional people skills. Versed in strategic planning, financial analysis and project management.\",\n",
            "    \"work_experience\": [\n",
            "        {\n",
            "            \"company\": \"Company Name, City, State\",\n",
            "            \"job_title\": \"Senior Director of Finance\",\n",
            "            \"dates\": \"May 2012 - Feb 2016\",\n",
            "            \"responsibilities\": [\n",
            "                \"Manage a team that is responsible for timely and accurate reporting for Commercial Accounts ($3.5BN) and Middle Market ($7BN) monthly and quarterly production results, including preparing Sr. Leadership for Investor Days, Earnings Releases, and Shareholder Meetings.\",\n",
            "                \"Lead a variety of projects including the coordination and consolidation of the annual plan, the annual field compensation process, as well as being the finance representative on a long-term strategic operating model project.\",\n",
            "                \"Drive CFO and Sr. Leadership directed projects in order to support evolving business needs including the development of an audit estimation process across Middle Market, implemented a new profitability measure which allowed detailed segmentation of the Middle Market book of business, and managed the re-alignment of the geographical footprint of our business (over 3,000 people across the country) to better drive results and synergy across business units.\",\n",
            "                \"Utilize exceptional analytical and communication skills across multiple levels of the organization, with an ability to understand the details as well as find and summarize key findings.\"\n",
            "            ]\n",
            "        ,\n",
            "        {\n",
            "            \"company\": \"Company Name, City, State\",\n",
            "            \"job_title\": \"Director of Strategic Initiatives\",\n",
            "            \"dates\": \"Jun 2009 - May 2012\",\n",
            "            \"responsibilities\": [\n",
            "                \"Developed strategy, identified priorities, and established business cases across and within the businesses to enable the successful delivery of strategic activities and investments.\",\n",
            "                \"Projects included re-designing underwriting documentation across Business Insurance, developing solutions to improve regulatory pricing documentation across Business Insurance, and streamlining the staff and process for Global Underwriting business.\",\n",
            "                \"Worked with leaders to develop solutions to change the business model and the operating model by determining ways to re-tool, re-align, re-organize, or create efficiencies in current activities.\",\n",
            "                \"Provided continuous support to senior management on planning, execution, market-specific needs, and challenges by providing fact-based decision support, and clear and concise messaging through meetings and presentations.\"\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"company\": \"Company Name, City, State\",\n",
            "            \"job_title\": \"Process Improvement Engineer\",\n",
            "            \"dates\": \"Jul 2006 - Jun 2009\",\n",
            "            \"responsibilities\": [\n",
            "                \"Completed a Liquid Petroleum Gas market study for National Programs and identified 10 new states in which they should expand their business, equal to an estimated $12 million dollars in premium.\",\n",
            "                \"Conducted an Account Manager job-assessment for Northland Insurance with the end goal of establishing metrics to measure the performance of 18 Account Managers on a monthly basis.\",\n",
            "                \"This study included interviewing, studying workloads and process time, and ultimately working with Management to develop performance measure metrics.\",\n",
            "                \"Assisted business areas with improving their operational performance by working through the process engineering methodology which consists of project planning, core data collection, process documentation, preliminary data analysis, the development of recommendations, and final report presentation.\",\n",
            "                \"Managed an Architects & Engineers process improvement project focused on finding opportunities to simplify the A & E's work environment.\",\n",
            "                \"This was accomplished through a division of labor comparison between 17 employees and another business unit, an assessment of streamlining opportunities along with an identification of work that can be performed outside the office.\",\n",
            "                \"Managed an Employee Relations process improvement project where I interviewed, created process workflow documents, and identified over 80 process improvement opportunities that were built into their 2008 business plan.\",\n",
            "                \"1st Rotation: Home Office Assistant Regional Financial Officer for Domestic Companies Provided financial and strategic planning analytical support to the Domestic Financial Officers in the Domestic Finance Teams for Travelers of Florida, Travelers of New Jersey and Premier.\",\n",
            "                \"Visited these field offices at least once a month, and acted as the liaison between the Domestic Companies and the Home Office.\"\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"education\": [\n",
            "        {\n",
            "            \"degree\": \"Bachelor of Science\",\n",
            "            \"major\": \"Economics and Finance\",\n",
            "            \"institution\": \"Bentley College\",\n",
            "            \"graduation_date\": \"May 2006\"\n",
            "        },\n",
            "        {\n",
            "            \"degree\": \"MBA\",\n",
            "            \"major\": null,\n",
            "            \"institution\": \"University of Connecticut Graduate School\",\n",
            "            \"graduation_date\": \"2012\"\n",
            "        }\n",
            "    ],\n",
            "    \"skills\": [\n",
            "        \"Premier\",\n",
            "        \"streamline\",\n",
            "        \"book\",\n",
            "        \"business plan\",\n",
            "        \"communication skills\",\n",
            "        \"concise\",\n",
            "        \"data analysis\",\n",
            "        \"data collection\",\n",
            "        \"decision support\",\n",
            "        \"delivery\",\n",
            "        \"designing\",\n",
            "        \"documentation\",\n",
            "        \"Employee Relations\",\n",
            "        \"senior management\",\n",
            "        \"Finance\",\n",
            "        \"Financial\",\n",
            "        \"Home Office\",\n",
            "        \"Insurance\",\n",
            "        \"investments\",\n",
            "        \"Leadership\",\n",
            "        \"Market\",\n",
            "        \"Meetings\",\n",
            "        \"messaging\",\n",
            "        \"Access\",\n",
            "        \"Excel\",\n",
            "        \"office\",\n",
            "        \"Power Point\",\n",
            "        \"presentations\",\n",
            "        \"pricing\",\n",
            "        \"process engineering\",\n",
            "        \"process improvement\",\n",
            "        \"project planning\",\n",
            "        \"reporting\",\n",
            "        \"strategy\",\n",
            "        \"strategic\",\n",
            "        \"strategic planning\",\n",
            "        \"Underwriting\",\n",
            "        \"Visio\",\n",
            "        \"Workbench\",\n",
            "        \"workflow\"\n",
            "    ]\n",
            "}\n",
            "```\n",
            "--------------------------------------------------\n",
            "Processing image 18/20: 17847636.jpg\n",
            "Loading image: /content/processed_images/17847636.jpg\n",
            "Loading extracted text: /content/tesseract_output/17847636.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1086\n",
            "Output Token Count: 682\n",
            "Total Token Count: 2872\n",
            "Saved extracted information to /content/json_output/17847636.json\n",
            "--------------------------------------------------\n",
            "Processing image 19/20: 19446337.jpg\n",
            "Loading image: /content/processed_images/19446337.jpg\n",
            "Loading extracted text: /content/tesseract_output/19446337.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1438\n",
            "Output Token Count: 837\n",
            "Total Token Count: 5676\n",
            "Saved extracted information to /content/json_output/19446337.json\n",
            "--------------------------------------------------\n",
            "Processing image 20/20: 17818707.jpg\n",
            "Loading image: /content/processed_images/17818707.jpg\n",
            "Loading extracted text: /content/tesseract_output/17818707.txt\n",
            "Extracting information from image and text..\n",
            "Input Token Count: 1582\n",
            "Output Token Count: 1170\n",
            "Total Token Count: 5929\n",
            "Saved extracted information to /content/json_output/17818707.json\n",
            "--------------------------------------------------\n",
            "Information Extraction Completed.\n",
            "Total time taken: 562.326639175415 seconds\n"
          ]
        }
      ]
    }
  ]
}